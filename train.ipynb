{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test GPU+CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T20:47:24.979999Z",
     "start_time": "2020-06-10T20:47:18.836006Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'1.8.0'"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T20:47:24.989004Z",
     "start_time": "2020-06-10T20:47:24.983998Z"
    }
   },
   "outputs": [],
   "source": [
    "# a = tf.constant([1.0, 2.0, 3.0 ,4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "# b = tf.constant([1.0, 2.0, 3.0 ,4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "# c = tf.matmul(a, b)\n",
    "\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "# print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T20:47:29.654058Z",
     "start_time": "2020-06-10T20:47:24.993004Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 5561530569249808738\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 1479989657\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 13033214203976661813\nphysical_device_desc: \"device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n]\n"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "+ 手写字体：\n",
    "    1. 上传自己的手写图片灰阶照片 \n",
    "    <p align=\"center\">\n",
    "      <img src=\"handwriting_preparation\\images\\yun.jpg\" alt=\"handwritten-pic\",  width=\"600\"/>\n",
    "    </p>\n",
    "    \n",
    "    2. 使用Tesseract+jTessBoxEditor获取每个charactor的内容与坐标box坐标信息\n",
    "    \n",
    "    <p align=\"center\">\n",
    "      <img src=\"README.asserts/char_box.png\" alt=\"char-box\",  width=\"400\"/>\n",
    "    </p>\n",
    "    \n",
    "    每个字对应的box信息：\n",
    "    <p align=\"center\">\n",
    "      <img src=\"README.asserts/box.png\" alt=\"box-info\",  width=\"400\"/>\n",
    "    </p>\n",
    "+ 书法字体（target）：\n",
    "    \n",
    "    1. 由于名家书法作品图片不够齐全，所以使用ttf格式的计算机编码字体生成图像\n",
    "    2. 对比之后，选用“迷你简黄草”字体\n",
    "    <p align=\"center\">\n",
    "      <img src=\"README.asserts/font_viewer.png\" alt=\"char-box\",  width=\"400\"/>\n",
    "    </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T20:47:29.664058Z",
     "start_time": "2020-06-10T20:47:29.659071Z"
    }
   },
   "outputs": [],
   "source": [
    "# !python font2img_finetune.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "# 制作数据集\n",
    "\n",
    "+ 将**手写字体**-**书法字体**pairwise地生成图片，组成数据集\n",
    "    <p align=\"center\">\n",
    "      <img src=\"data\\paired_images_finetune\\136_0000.jpg\" alt=\"pairwise\",  width=\"200\"/>\n",
    "      <img src=\"data\\paired_images_finetune\\136_0001.jpg\" alt=\"pairwise\",  width=\"200\"/>\n",
    "      <img src=\"data\\paired_images_finetune\\136_0002.jpg\" alt=\"pairwise\",  width=\"200\"/>\n",
    "      <img src=\"data\\paired_images_finetune\\136_0003.jpg\" alt=\"pairwise\",  width=\"200\"/>\n",
    "      <img src=\"data\\paired_images_finetune\\136_0004.jpg\" alt=\"pairwise\",  width=\"200\"/>\n",
    "      <img src=\"data\\paired_images_finetune\\136_0005.jpg\" alt=\"pairwise\",  width=\"200\"/>\n",
    "      <img src=\"data\\paired_images_finetune\\136_0006.jpg\" alt=\"pairwise\",  width=\"200\"/>\n",
    "    </p>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T20:47:29.803054Z",
     "start_time": "2020-06-10T20:47:29.669057Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from model.preprocessing_helper import CANVAS_SIZE, EMBEDDING_DIM\n",
    "from model.unet import UNet\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T20:47:29.818054Z",
     "start_time": "2020-06-10T20:47:29.806059Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################ train-params ###############\n",
    "\n",
    "experiment_dir='experiments_finetune'    # experiment directory, data, samples,checkpoints,etc\n",
    "experiment_id=1         # sequence id for the experiments you prepare to run\n",
    "image_size=CANVAS_SIZE  # size of your input and output image\n",
    "L1_penalty=100      # weight for L1 loss\n",
    "Lconst_penalty=15   # weight for const loss\n",
    "Ltv_penalty=0.0     # weight for tv loss\n",
    "Lcategory_penalty=1.0  # weight for tv loss\n",
    "embedding_num=40   # number for distinct embeddings\n",
    "embedding_dim=EMBEDDING_DIM   # dimension for embedding\n",
    "epoch=10         # number of epoch\n",
    "batch_size=16    # number of examples in batch\n",
    "lr=0.001         # initial learning rate for adam\n",
    "schedule=20         # number of epochs to half learning rate\n",
    "resume=1            # number of epochs to half learning rate\n",
    "resume_pre_model=0  # resume from pre-training\n",
    "freeze_encoder_decoder=1      # freeze encoder/decoder weights during training\n",
    "optimizer='adam'   # optimizer of the model\n",
    "fine_tune=None    # specific labels id to be fine tuned\n",
    "inst_norm=1      # use conditional instance normalization in your model\n",
    "sample_steps=20  # number of batches in between two samples are drawn from validation set\n",
    "checkpoint_steps=50  # number of batches in between two checkpoints\n",
    "validate_steps=1     # number of batches in between two validations\n",
    "validate_batches=20  # validation epochs\n",
    "flip_labels=1    # whether flip training data labels or not, in fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T21:01:53.677280Z",
     "start_time": "2020-06-10T20:47:29.823054Z"
    },
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "freeze encoder/decoder weights\nunpickled total 86 examples\nunpickled total 10 examples\ntrain examples -> 86, val examples -> 10\n==========\n\nNone\n\n==============\nfail to restore model experiments_finetune\\checkpoint\\experiment_1\nfail to restore model experiments_finetune\\checkpoint\\experiment_1\nresume the pre-trained model.....\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    model = UNet(experiment_dir=experiment_dir, batch_size=batch_size, experiment_id=experiment_id,\n",
    "                 input_width=image_size, output_width=image_size, embedding_num=embedding_num,\n",
    "                 validate_batches=validate_batches, embedding_dim=embedding_dim,\n",
    "                 L1_penalty=L1_penalty, Lconst_penalty=Lconst_penalty,\n",
    "                 Ltv_penalty=Ltv_penalty, Lcategory_penalty=Lcategory_penalty)\n",
    "    model.register_session(sess)\n",
    "    if flip_labels:\n",
    "        model.build_model(is_training=True, inst_norm=inst_norm, no_target_source=True)\n",
    "    else:\n",
    "        model.build_model(is_training=True, inst_norm=inst_norm)\n",
    "    fine_tune_list = None\n",
    "    if fine_tune:\n",
    "        ids = fine_tune.split(\",\")\n",
    "        fine_tune_list = set([int(i) for i in ids])\n",
    "#         print(\"@@@@@\"+str(fine_tune_list))\n",
    "\n",
    "    model.train(lr=lr, epoch=epoch, resume=resume, resume_pre_model=resume_pre_model,\n",
    "                schedule=schedule, freeze_encoder_decoder=freeze_encoder_decoder,\n",
    "                fine_tune=fine_tune_list,\n",
    "                sample_steps=sample_steps, checkpoint_steps=checkpoint_steps,\n",
    "                validate_steps=validate_steps,\n",
    "                flip_labels=flip_labels, optimizer=optimizer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 289.666666,
   "position": {
    "height": "40px",
    "left": "841px",
    "right": "20px",
    "top": "61px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}